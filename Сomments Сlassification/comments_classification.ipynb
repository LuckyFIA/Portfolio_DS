{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4506100-7c04-455e-a6ff-e9a87366efc9",
   "metadata": {},
   "source": [
    "# Анализ текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749c4054-9836-42bf-9dae-2b6425a4c514",
   "metadata": {},
   "source": [
    "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Необходимо построить модель умеющую классифицировать комментарии на позитивные и негативные, со значением метрики качества *F1* не менее 0.75.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "210ee13d-d33e-4983-8683-e1d26049b1e2",
   "metadata": {},
   "source": [
    "!pip install torch --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "raw",
   "id": "45fab6d2-9c4a-4a58-8a7c-6b5859589bdc",
   "metadata": {
    "tags": []
   },
   "source": [
    "!pip install protobuf==3.20.3 --user"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f93e94fb-ffe1-4463-8263-6fcb22129fba",
   "metadata": {
    "tags": []
   },
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68bdda4b-20bd-4fff-8756-ad55660cb5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем библиотеки\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa502a1-a0e6-4912-9b41-e0487714f449",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d548bb-4052-4ce1-b89e-d4650ae21995",
   "metadata": {},
   "source": [
    "### Обзор данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7d86a8-7bfa-4abd-bd4e-308c605db45c",
   "metadata": {},
   "source": [
    "**Откроим файл с данными, изучим общую информацию.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40410fec-50ba-4a78-98bc-ec1e9dc9c434",
   "metadata": {},
   "outputs": [],
   "source": [
    "pth1 = '/datasets/toxic_comments.csv'\n",
    "pth2 = 'https://restricted/datasets/toxic_comments.csv'\n",
    "\n",
    "if os.path.exists(pth1):\n",
    "    data = pd.read_csv(pth1)\n",
    "else:\n",
    "    try:\n",
    "        data = pd.read_csv(pth2)\n",
    "    except:\n",
    "        print('Что-то не так, файл с данными не найден!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4529717-af2d-4e62-9538-8e8e0fd1ba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Уменьшим размер df в связи с аппаратными ограничениями \n",
    "data = data.sample(4000, random_state=22).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "474a5878-1ece-4306-aeb5-fb8deb78dd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведем общую инф о df\n",
    "def df_info(df):\n",
    "    display(df.head())\n",
    "    display(df.info())\n",
    "    display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "876cab16-802d-43d2-be02-d3290fb48af9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111987</td>\n",
       "      <td>(1) Not that I can think of. (2) I'm not sure....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80940</td>\n",
       "      <td>\"\\n\\n Email \\n\\nHiya,\\n\\nEmail for you. Can yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103441</td>\n",
       "      <td>If what you've found isn't WP:OR then please g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122458</td>\n",
       "      <td>\"\\n\\n Please do not vandalize pages, as you di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58876</td>\n",
       "      <td>Danny Green article peer review \\n\\nThis artic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0      111987  (1) Not that I can think of. (2) I'm not sure....      0\n",
       "1       80940  \"\\n\\n Email \\n\\nHiya,\\n\\nEmail for you. Can yo...      0\n",
       "2      103441  If what you've found isn't WP:OR then please g...      0\n",
       "3      122458  \"\\n\\n Please do not vandalize pages, as you di...      0\n",
       "4       58876  Danny Green article peer review \\n\\nThis artic...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  4000 non-null   int64 \n",
      " 1   text        4000 non-null   object\n",
      " 2   toxic       4000 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 93.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>80053.370000</td>\n",
       "      <td>0.099750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>45943.627098</td>\n",
       "      <td>0.299704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39742.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>81476.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>118949.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>159434.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0        toxic\n",
       "count    4000.000000  4000.000000\n",
       "mean    80053.370000     0.099750\n",
       "std     45943.627098     0.299704\n",
       "min        14.000000     0.000000\n",
       "25%     39742.250000     0.000000\n",
       "50%     81476.000000     0.000000\n",
       "75%    118949.750000     0.000000\n",
       "max    159434.000000     1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_info(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528197c6-660f-4e31-b134-efd8d5fe9495",
   "metadata": {},
   "source": [
    "Данные представлены следующими признаками:\n",
    "- `text` — содержит текст комментария;\n",
    "- `toxic` — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8655df8-b314-4fd3-b7e8-6cac5232cb4d",
   "metadata": {},
   "source": [
    "Пропуски в данных отсутствуют, однако наблюдается явный дисбаланс классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d2b75e4-9d91-4a31-9d09-6c12e37f78de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.90025\n",
       "1    0.09975\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts(normalize = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a183d13-95f8-40e9-acea-34397c335d3d",
   "metadata": {},
   "source": [
    "Соотношение классов в целевом признаке: ~ 10 / 90. Мы имеем дисбаланс классов. Учтем этот факт в дальнейшей работе"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d04d815-216f-481a-a4c6-dc96bb66181c",
   "metadata": {},
   "source": [
    "Целевой признак `toxic` — факт токсичности коментария. Будем решать задачу методами классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4889f14b-3c0f-475e-8a77-63b96cfc85a6",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb06b5fd-a141-43a0-be9a-81af339f12f4",
   "metadata": {},
   "source": [
    "**Подготовим признаки с помощью BERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0b92018-e3c7-439a-8436-c0728d96ff85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Используем GPU для ускорения расчетов\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86353981-e2cf-4ae7-8ca1-0988e729b8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at unitary/toxic-bert were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Загружаем модель\n",
    "model_name = 'unitary/toxic-bert' # Предобученная модель\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name, do_lower_case=True) # Инициализируем токенайзер\n",
    "model = transformers.AutoModel.from_pretrained(model_name).to(device) # Инициализируем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adea94c8-5839-4795-b6bd-fdfcd3a42d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем исходные тексты в список токенов с макс длинной текста 512 символа\n",
    "tokenized = data['text'].apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True,truncation=True, max_length=512))\n",
    "\n",
    "# Найдем максимальную длину векторов после токенизации\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "#Применим метод padding, чтобы после токенизации длины исходных текстов в корпусе были равными\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "# Поясним модели, что нули не несут значимой информации\n",
    "attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a03a856a-ed69-4c04-8cff-3f185fa2a8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96323aed3f764be8ba9221a2e128a540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# преобразование текстов в эмбеддинги\n",
    "batch_size = 100\n",
    "\n",
    "# сделаем пустой список для хранения эмбеддингов твитов\n",
    "embeddings = []\n",
    "\n",
    "# цикл по батчам\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        # преобразуем данные\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]).to(device)\n",
    "        # преобразуем маску\n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)]).to(device)\n",
    "        \n",
    "        # Получение эмбеддингов\n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        embeddings.append(batch_embeddings[0][:,0,:].cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75556238-b9e6-4307-ad00-e4db40b290ed",
   "metadata": {},
   "source": [
    "Разделим данные на обучающую и тестовую выборки в соотношении 80:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "994641ad-b2bc-40c5-b628-527191843714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность тренеровочных данных (3200, 768)\n",
      "Размерность тестовых данных (800, 768)\n"
     ]
    }
   ],
   "source": [
    "# Подготовим признаки\n",
    "features = np.concatenate(embeddings)\n",
    "target = data['toxic']\n",
    "\n",
    "# Разделим данные\n",
    "(features_train, features_test,\n",
    "     target_train, target_test) = train_test_split(features, target,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=22,\n",
    "                                                   stratify = target)\n",
    "print(\"Размерность тренеровочных данных\", features_train.shape)\n",
    "print(\"Размерность тестовых данных\", features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbae934b-a8e5-4986-b08b-4a6721e097c9",
   "metadata": {},
   "source": [
    "На данном этапе произведена загрузка данных и их подготовка:\n",
    "- Для решения задачи предоставлен набор данных с разметкой о токсичности правок;\n",
    "- Пропуски в данных отсутствуют;\n",
    "- Наблюдается дисбаланс классов в целевом признаке ~ 10 / 90;\n",
    "- Признаки подготовлены с помощью нейросети BERT;\n",
    "- Данные разделены на обучающую и тестовую выборки в соотношении 80:20."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7873bf-ec1d-47d3-99eb-2263395cfe87",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01df2083-b68c-46d4-b2bc-3bd0398c02a7",
   "metadata": {},
   "source": [
    "Проведем обучение трех моделей: `LogisticRegression`, `LGBMClassifier`, `RandomForestClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff45456-3fd4-472d-8009-2551f7c9a872",
   "metadata": {},
   "source": [
    "### Модель на основе LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "455532f1-b674-4641-90f1-5c62ecb1278f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "best params {'C': 1, 'class_weight': 'balanced', 'penalty': 'l2', 'random_state': 22, 'solver': 'liblinear'} \n",
      "score 0.932\n",
      "CPU times: total: 672 ms\n",
      "Wall time: 5.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_lgr = LogisticRegression()\n",
    "\n",
    "param_grid_lgr = {\n",
    "    'penalty': [\"l1\",\"l2\"],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'solver': ['liblinear'],\n",
    "    'random_state': [22],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Обучение\n",
    "cv_lgr = GridSearchCV(estimator=model_lgr,\n",
    "                      param_grid=param_grid_lgr,\n",
    "                      cv=3,\n",
    "                      n_jobs=-1,\n",
    "                      scoring='f1',\n",
    "                      verbose=10\n",
    "                     )\n",
    "cv_lgr.fit(features_train, target_train)\n",
    "\n",
    "cv_lgr_best_params = cv_lgr.best_params_\n",
    "cv_lgr_best_score = round(cv_lgr.best_score_, 3)\n",
    "\n",
    "cv_lgr_results = ['LogisticRegression',\n",
    "                  cv_lgr_best_score]\n",
    "\n",
    "print(\"best params\", cv_lgr_best_params, \"\\nscore\", cv_lgr_best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff10093-e37e-4207-b214-5d83dea348c0",
   "metadata": {},
   "source": [
    "### Модель на основе LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5ef6077-b494-4e00-af88-456ea137b2f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 28 candidates, totalling 84 fits\n",
      "best params {'class_weight': 'balanced', 'learning_rate': 0.03, 'max_depth': 25, 'n_estimators': 300} \n",
      "score 0.9\n",
      "CPU times: total: 35.9 s\n",
      "Wall time: 10min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_lgb = LGBMClassifier()\n",
    "\n",
    "param_grid_lgb = {\n",
    "    'max_depth': [25, 50],\n",
    "    'learning_rate' : [0.01, 0.03],\n",
    "    'n_estimators': range(100, 800, 100),\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "cv_lgb = GridSearchCV(estimator=model_lgb,\n",
    "                      param_grid=param_grid_lgb,\n",
    "                      cv=3,\n",
    "                      n_jobs=-1,\n",
    "                      scoring='f1',\n",
    "                      verbose=1\n",
    "                     )\n",
    "cv_lgb.fit(features_train, target_train)\n",
    "\n",
    "cv_lgb_best_params = cv_lgb.best_params_\n",
    "cv_lgb_best_score = round(cv_lgb.best_score_, 1)\n",
    "\n",
    "cv_lgb_results = ['LightGBM',\n",
    "                  cv_lgb_best_score]\n",
    "\n",
    "print(\"best params\", cv_lgb_best_params, \"\\nscore\", cv_lgb_best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e60682d-a89b-4dfa-9131-6dde5c9de100",
   "metadata": {},
   "source": [
    "### Модель на основе RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "008f9108-83ce-4c49-9a83-d0b7c3bce198",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 80 candidates, totalling 240 fits\n",
      "best params {'class_weight': 'balanced', 'max_depth': 5, 'n_estimators': 210, 'random_state': 22} \n",
      "score 0.941\n",
      "CPU times: total: 3.84 s\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_rfс = RandomForestClassifier()\n",
    "\n",
    "param_grid_rfс = {\n",
    "        'n_estimators': range(10, 410, 50),\n",
    "        'max_depth' : [None] + [i for i in range(2, 11)],\n",
    "        'random_state': [22],\n",
    "        'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "# Обучение\n",
    "cv_rfс = GridSearchCV(estimator=model_rfс, \n",
    "                      param_grid=param_grid_rfс, \n",
    "                      cv=3,\n",
    "                      n_jobs=-1,\n",
    "                      scoring='f1',\n",
    "                      verbose=1\n",
    "                     )\n",
    "cv_rfс.fit(features_train, target_train)\n",
    "\n",
    "cv_rfс_best_params = cv_rfс.best_params_\n",
    "cv_rfс_best_score = round(cv_rfс.best_score_, 3)\n",
    "\n",
    "cv_rfс_results = ['RandomForest', \n",
    "                  cv_rfс_best_score]\n",
    "\n",
    "print(\"best params\", cv_rfс_best_params, \"\\nscore\", cv_rfс_best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b9a9cc-951f-4696-b5d7-f17f9d4b081a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Анализ моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f89d0e-1873-4776-9e14-fd97b257433a",
   "metadata": {},
   "source": [
    "Сведем полученные в ходе обучения и кросвалидации моделей данные в таблицу, оценим качество предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39ccaae9-8dd4-4372-a7f9-be6d69132fc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>Качество предсказания (F1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Модель  Качество предсказания (F1)\n",
       "0        RandomForest                       0.941\n",
       "1  LogisticRegression                       0.932\n",
       "2            LightGBM                       0.900"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_analytics = pd.DataFrame([cv_rfс_results, cv_lgr_results, cv_lgb_results], \n",
    "                        columns=['Модель', 'Качество предсказания (F1)'])\n",
    "model_analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eba827-c645-4b1a-8547-b9d5f0756095",
   "metadata": {},
   "source": [
    "Исследование проводилось для трех моделей: `LogisticRegression`, `LGBMClassifier`, `RandomForestClassifier`.  \n",
    "В результате при помощи `GridSearchCV` были подобраны оптимальные параметры, проведено обучение моделей а так же проанализировано качество моделей.  \n",
    "Все модели удовлетворяют заданному условию - Значение метрики F1 не меньше 0.75.  \n",
    "Однако по итогам кросвалидации победителем является модель `RandomForestClassifier` со значение метрики F1 - 0,941.\n",
    "\n",
    "Опираясь на требования заказчика, для дальнейшей работы рекомендуем применять модель на основе `RandomForestClassifier` со следующими гиперпараметрами 'class_weight': 'balanced', 'max_depth': 5, 'n_estimators': 210."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27586a7-a146-42e2-9cb9-cc128fa759fd",
   "metadata": {},
   "source": [
    "### Тестирование лучшей модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35392160-ce9e-4089-9622-c6ffb9ae8cfc",
   "metadata": {
    "tags": []
   },
   "source": [
    "Проведем финальное тестирование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da47d038-d9af-47bf-9699-79300b532705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# функция для анализа моделей\n",
    "def model_analysis (features_train, target_train, features_test, target_test, model, model_name):\n",
    "    start = time.time()    \n",
    "    model.fit(features_train, target_train)\n",
    "    end = time.time()\n",
    "    fit_time = round(end - start, 3)\n",
    "    \n",
    "    start = time.time()\n",
    "    model_pred = model.predict(features_test)\n",
    "    end = time.time()\n",
    "    pred_time = round(end - start, 3)\n",
    "    \n",
    "    score = round(f1_score(target_test, model_pred), 3)\n",
    "    \n",
    "    return [model_name, score, fit_time, pred_time]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfb47144-d387-4751-8081-8d52fd4db998",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель: RandomForestClassifier \n",
      "Качество предсказания (F1): 0.958 \n",
      "Время обучения модели: 3.111 сек. \n",
      "Время предсказания модели: 0.019 сек.\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(**cv_rfс_best_params)\n",
    "model = model_analysis(features_train, target_train, features_test, target_test, model, 'RandomForestClassifier')\n",
    "\n",
    "print('Модель:', model[0], \n",
    "     '\\nКачество предсказания (F1):', model[1],\n",
    "     '\\nВремя обучения модели:', model[2], 'сек.',\n",
    "     '\\nВремя предсказания модели:', model[3], 'сек.',\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2c391f-3baa-4002-b87e-896996dde5a4",
   "metadata": {},
   "source": [
    "## Общий вывод исследования"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b0dab1-628a-407b-bb92-1d9749c721a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "В нашем распоряжении набор данных с разметкой о токсичности правок.  \n",
    "Перед нами была поставлена задача:  \n",
    "**Построить модель умеющую классифицировать комментарии на позитивные и негативные.**  \n",
    "\n",
    "Из особенностей:\n",
    "- Размер тестовой выборки - 10% от исходных данных;\n",
    "- Значение метрики F1 на тестовой выборке должно быть не менее 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b6f51e-c024-4f61-84b3-9e6380c5592c",
   "metadata": {},
   "source": [
    "Работа проходила в несколько этапов:\n",
    "1. Подготовка данных:\n",
    "    - Обзор данных:\n",
    "        - Данные представлены следующими признаками:\n",
    "            - `text` — содержит текст комментария;\n",
    "            - `toxic` — факт токсичности коментария, целевой признак.\n",
    "        - Пропуски в данных отсутствуют;\n",
    "        - Наблюдается дисбаланс классов в целевом признаке ~ 10/90, учтен при обучении моделей.\n",
    "    - Подготовка данных:\n",
    "        - Подготовили признаки с помощью нейросети BERT;\n",
    "        - Создали признаки;\n",
    "        - Разделим данные на обучающую и тестовую выборки в соотношении 80:20.\n",
    "2. Обучение моделей:\n",
    "     - При помощи `GridSearchCV` провели обучение с кросвалидацией для следующих моделей:\n",
    "        - LogisticRegression;\n",
    "        - LGBMClassifier;\n",
    "        - RandomForestClassifier.\n",
    "    - На основе метрики F1, выявленой при кросвалидации, выбрали лучшую модель - `RandomForestClassifier`\n",
    "3. Провели финальное тестирование модели на тестовой выборке:\n",
    "    - Модель RandomForestClassifier: \n",
    "        - Качество предсказания (F1): 0.958;\n",
    "        - Время обучения модели: 3.13 сек;\n",
    "        - Время предсказания модели: 0.019 сек;\n",
    "        - Гиперпараметры: class_weight': 'balanced', 'max_depth': 5, 'n_estimators': 210.\n",
    "\n",
    "\n",
    "Таким образом поставленная задача реализована с учетом особенностей и пожеланий заказчика."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
